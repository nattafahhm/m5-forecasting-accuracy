{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMdd/7AktCRyhfteyy2l1Sf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Setting up the Development Environment"],"metadata":{"id":"DxFCd8caC_jR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HK1k-g5_meKs"},"outputs":[],"source":["# setup development environment \n","from google.colab import drive\n","import warnings\n","import logging\n","drive.mount('/content/drive', force_remount=True)\n","warnings.filterwarnings(\"ignore\")\n","logger = logging.getLogger('cmdstanpy')\n","logger.addHandler(logging.NullHandler())\n","logger.propagate = False\n","logger.setLevel(logging.CRITICAL)\n","\n","# import libraries in Python\n","import pandas as pd\n","import numpy as np\n","from downcast import reduce\n","from tqdm import tqdm\n","import random\n","\n","# setup working directory \n","WORK_DIR = 'drive/MyDrive/TaoBin'"]},{"cell_type":"markdown","source":["## Data pre-processing"],"metadata":{"id":"EgPoe3Z2JKT7"}},{"cell_type":"code","source":["class Preprocess():\n","  \"\"\"\n","  Preprocess contains all the data preprocessing steps to convert raw data into the processed form for machine learning\n","  \"\"\"\n","\n","  random.seed(23)\n","\n","  def read_data(self):\n","    \"Read a comma-separated values (csv) file into DataFrame\"\n","\n","    self.sales = pd.read_csv(f'{WORK_DIR}/raw_data/sales_train_evaluation.csv')\n","    self.sell_prices = pd.read_csv(f'{WORK_DIR}/raw_data/sell_prices.csv')\n","    self.calendar = pd.read_csv(f'{WORK_DIR}/raw_data/calendar.csv')\n","\n","    self.sales, self.sell_prices, self.calendar = self.downcast(self.sales, self.sell_prices, self.calendar)\n","\n","    return self.sales, self.sell_prices, self.calendar\n","\n","  def downcast(self, sales, sell_prices, calendar):\n","    \"Reduce pandas data-frame size using downcast\"\n","    sales = reduce(sales)\n","    sell_prices = reduce(sell_prices)\n","    calendar = reduce(calendar)\n","\n","    return sales, sell_prices, calendar\n","  \n","  def lag_features(self, data):\n","    \"Add Lag features. a.k.a values at prior time steps.\"\n","\n","    day_lags = [28, 35, 42, 49, 56, 63, 70]\n","    print(day_lags)\n","\n","    for lag in tqdm(day_lags):\n","      data[\"lag_\" + str(lag)] = data.groupby(\"id\")[\"sales\"].shift(lag).astype(np.float16)\n","  \n","    return data\n","\n","  def feature_engineering(self, sales, sell_prices, calendar):\n","    \"Selecting, manipulating, and transforming raw data into features that can be used in supervised learning.\"\n","\n","    # create new date features required for the time-series prediction.\n","    start_date = 1942\n","    end_date = 1942+28\n","    for day in tqdm(range(start_date, end_date)):\n","      sales['d_' + str(day)] = np.int32(0)\n","\n","    # define all categorical columns.\n","    cat_cols = [\"id\", \"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\"]\n","    self.data = pd.melt(sales, id_vars=cat_cols, var_name='day', value_name='sales').dropna()\n","    \n","    # merge DataFrame\n","    self.data = self.data.merge(calendar, left_on='day', right_on='d')\n","    self.data = self.data.merge(sell_prices,on=['store_id','item_id', 'wm_yr_wk'], how='left')\n","    \n","    # compute mean of groups, excluding missing values.\n","    self.data['sell_price'].fillna(self.data.groupby('id')['sell_price'].transform('mean'), inplace=True)\n","    \n","    # strip the 'd_' from the day column to make it an integer feature.\n","    self.data['day'] = self.data['day'].apply(lambda x: x.split('_')[1]).astype(np.int16)\n","    \n","    # drop specified labels from rows or columns.\n","    self.data.drop(['d','weekday','date'], axis=1, inplace=True) \n","\n","    # categorical data encoding\n","    for i in self.data.columns:\n","        try:\n","            self.data[i] = self.data[i].cat.codes\n","        except AttributeError:\n","            pass\n","\n","    # add lag features\n","    self.data = self.lag_features(self.data)\n","\n","    return self.data"],"metadata":{"id":"ScF1DzJBngEn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    pre = Preprocess()\n","\n","    # sales, sell_prices, calendar = pre.read_data()\n","    # sales.to_pickle(f'{WORK_DIR}/processed_data/downcast_sales.pkl')\n","    # sell_prices.to_pickle(f'{WORK_DIR}/processed_data/downcast_sell_prices.pkl')\n","    # calendar.to_pickle(f'{WORK_DIR}/processed_data/downcast_calendar.pkl')\n","\n","    # read dowcast data\n","    sales = pd.read_pickle(f'{WORK_DIR}/processed_data/downcast_sales.pkl')\n","    sell_prices = pd.read_pickle(f'{WORK_DIR}/processed_data/downcast_sell_prices.pkl')\n","    calendar = pd.read_pickle(f'{WORK_DIR}/processed_data/downcast_calendar.pkl')\n","\n","    # feature engineering\n","    data = pre.feature_engineering(sales, sell_prices, calendar)\n","    data = data[data['day']>1000]\n","\n","    # remove all rows with NaN value\n","    data.dropna(inplace=True)\n","    data.isna().sum().sum()\n","\n","    # save processed data\n","    data.to_pickle(f'{WORK_DIR}/processed_data/processed_data.pkl')\n"],"metadata":{"id":"u3pbR4RcoUK1"},"execution_count":null,"outputs":[]}]}